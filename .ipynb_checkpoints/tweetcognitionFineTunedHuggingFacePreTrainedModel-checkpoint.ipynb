{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "050a16a2-0353-48aa-b91a-0a96d333ff50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "Requirement already satisfied: openpyxl in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from openpyxl) (1.1.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "Requirement already satisfied: torch in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (2.0.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (11.7.4.91)\n",
      "Requirement already satisfied: networkx in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: sympy in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (10.9.0.58)\n",
      "Requirement already satisfied: typing-extensions in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (10.2.10.91)\n",
      "Requirement already satisfied: filelock in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (3.12.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: jinja2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (2.14.3)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (11.4.0.1)\n",
      "Requirement already satisfied: wheel in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.40.0)\n",
      "Requirement already satisfied: setuptools in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (67.6.1)\n",
      "Requirement already satisfied: lit in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from triton==2.0.0->torch) (16.0.3)\n",
      "Requirement already satisfied: cmake in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from triton==2.0.0->torch) (3.26.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-0.19.0-py3-none-any.whl (219 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 219 kB 12.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting psutil\n",
      "  Downloading psutil-5.9.5-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (282 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 282 kB 90.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from accelerate) (2.0.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from accelerate) (1.24.3)\n",
      "Requirement already satisfied: pyyaml in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from accelerate) (5.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from accelerate) (23.0)\n",
      "Requirement already satisfied: jinja2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch>=1.6.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch>=1.6.0->accelerate) (10.9.0.58)\n",
      "Requirement already satisfied: sympy in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch>=1.6.0->accelerate) (1.12)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch>=1.6.0->accelerate) (2.14.3)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch>=1.6.0->accelerate) (2.0.0)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch>=1.6.0->accelerate) (11.4.0.1)\n",
      "Requirement already satisfied: filelock in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch>=1.6.0->accelerate) (3.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch>=1.6.0->accelerate) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch>=1.6.0->accelerate) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch>=1.6.0->accelerate) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch>=1.6.0->accelerate) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch>=1.6.0->accelerate) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch>=1.6.0->accelerate) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch>=1.6.0->accelerate) (11.7.99)\n",
      "Requirement already satisfied: typing-extensions in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch>=1.6.0->accelerate) (4.5.0)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch>=1.6.0->accelerate) (11.7.91)\n",
      "Requirement already satisfied: networkx in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch>=1.6.0->accelerate) (3.1)\n",
      "Requirement already satisfied: wheel in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->accelerate) (0.40.0)\n",
      "Requirement already satisfied: setuptools in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->accelerate) (67.6.1)\n",
      "Requirement already satisfied: lit in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (16.0.3)\n",
      "Requirement already satisfied: cmake in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (3.26.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "Installing collected packages: psutil, accelerate\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "Successfully installed accelerate-0.19.0 psutil-5.9.5\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers --quiet\n",
    "!pip install datasets --quiet\n",
    "!pip install evaluate --quiet\n",
    "!pip install openpyxl\n",
    "!pip install torch\n",
    "!pip install -U scikit-learn scipy matplotlib --quiet\n",
    "!pip install --upgrade accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71782988-136c-4fc8-bd74-aa410fc838f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments, EarlyStoppingCallback, set_seed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import evaluate\n",
    "from sklearn.metrics import classification_report\n",
    "import datasets\n",
    "import math\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58eae7c6-b01c-4739-af43-6d22aa28e0c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text     0\n",
      "label    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Enthusiasm is rare, Endurance is rare.</td>\n",
       "      <td>GRADUATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>That amazing moment!</td>\n",
       "      <td>GRADUATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Work hard. Stay humble.;.;.;#graduating #gradu...</td>\n",
       "      <td>GRADUATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@nomi_9867 @BVBoni17 Education is key üñçÔ∏è</td>\n",
       "      <td>GRADUATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Big journey begins with small steps.;.;.;#gra...</td>\n",
       "      <td>GRADUATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>Was just told that my dear friend, Dr. Ramin O...</td>\n",
       "      <td>DEATH_OF_A_LOVED_ONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>@sy_fyn_ity I'm so sorry, how awful. My dad di...</td>\n",
       "      <td>DEATH_OF_A_LOVED_ONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>my other grandpa just died by a heart attack</td>\n",
       "      <td>DEATH_OF_A_LOVED_ONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>My grandma died last night. I knew it was comi...</td>\n",
       "      <td>DEATH_OF_A_LOVED_ONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>I'm so upset because finally everything was go...</td>\n",
       "      <td>DEATH_OF_A_LOVED_ONE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>876 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text                 label\n",
       "0               Enthusiasm is rare, Endurance is rare.            GRADUATION\n",
       "1                                 That amazing moment!            GRADUATION\n",
       "2    Work hard. Stay humble.;.;.;#graduating #gradu...            GRADUATION\n",
       "3             @nomi_9867 @BVBoni17 Education is key üñçÔ∏è            GRADUATION\n",
       "4     Big journey begins with small steps.;.;.;#gra...            GRADUATION\n",
       "..                                                 ...                   ...\n",
       "871  Was just told that my dear friend, Dr. Ramin O...  DEATH_OF_A_LOVED_ONE\n",
       "872  @sy_fyn_ity I'm so sorry, how awful. My dad di...  DEATH_OF_A_LOVED_ONE\n",
       "873      my other grandpa just died by a heart attack   DEATH_OF_A_LOVED_ONE\n",
       "874  My grandma died last night. I knew it was comi...  DEATH_OF_A_LOVED_ONE\n",
       "875  I'm so upset because finally everything was go...  DEATH_OF_A_LOVED_ONE\n",
       "\n",
       "[876 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### CLEANUP\n",
    "\n",
    "\n",
    "# Load labeled dataset of tweets related to specific life events\n",
    "df = pd.read_excel('dataset/LabeledTweets.xlsx', names=['text', 'label'])\n",
    "print(df.isna().sum())  # print the number of NaN values in each column\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9660a83b-7efb-4cfd-83b6-da557ce3bbec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>#GraduationDay of my #Champion #ShubhSharma ....</td>\n",
       "      <td>GRADUATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>After 13 years together, we decided to finall...</td>\n",
       "      <td>WEDDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>I‚Äôm officially divorced!!! Now I get to throw ...</td>\n",
       "      <td>DIVORCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>After months of budgeting and sacrifice, I've ...</td>\n",
       "      <td>PAID_OFF_DEBT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>Living with fibromyalgia means facing invisibl...</td>\n",
       "      <td>SERIOUS_HEALTH_CONDITION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>@IAmLouBates: I got a new job. https://t.co/...</td>\n",
       "      <td>NEW_JOB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>After #graduation, you can have a fun time la...</td>\n",
       "      <td>GRADUATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>Experiencing the shock of a flooded basement t...</td>\n",
       "      <td>DAMEGED_OR_STOLEN_PROPERTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>Cruising through life in my new convertible! T...</td>\n",
       "      <td>CAR_PURCHASE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>It's not the news I expected, but I'm determin...</td>\n",
       "      <td>SERIOUS_HEALTH_CONDITION</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>876 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text   \n",
       "41    #GraduationDay of my #Champion #ShubhSharma ....  \\\n",
       "132   After 13 years together, we decided to finall...   \n",
       "857  I‚Äôm officially divorced!!! Now I get to throw ...   \n",
       "327  After months of budgeting and sacrifice, I've ...   \n",
       "811  Living with fibromyalgia means facing invisibl...   \n",
       "..                                                 ...   \n",
       "243    @IAmLouBates: I got a new job. https://t.co/...   \n",
       "81    After #graduation, you can have a fun time la...   \n",
       "392  Experiencing the shock of a flooded basement t...   \n",
       "287  Cruising through life in my new convertible! T...   \n",
       "793  It's not the news I expected, but I'm determin...   \n",
       "\n",
       "                          label  \n",
       "41                   GRADUATION  \n",
       "132                     WEDDING  \n",
       "857                     DIVORCE  \n",
       "327               PAID_OFF_DEBT  \n",
       "811    SERIOUS_HEALTH_CONDITION  \n",
       "..                          ...  \n",
       "243                     NEW_JOB  \n",
       "81                   GRADUATION  \n",
       "392  DAMEGED_OR_STOLEN_PROPERTY  \n",
       "287                CAR_PURCHASE  \n",
       "793    SERIOUS_HEALTH_CONDITION  \n",
       "\n",
       "[876 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83d780af-4b9d-4395-978b-98c3e7228b46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 700\n",
      "})\n",
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 175\n",
      "})\n",
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 64\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8618e35144b420cb459990c9e6e1181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/700 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37e3f6f1ff724a96b80dc8f3c594f2ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/175 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8910bf6a415a46d4a73b072b3aa8cf96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/64 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "BATCH_SIZE = 16\n",
    "MODEL = 'cardiffnlBATCH_SIZEp/twitter-roberta-base-sep2022'\n",
    "dataset_dict = {}\n",
    "\n",
    "train_df = df.head(math.trunc(len(df)*0.8))\n",
    "test_df = df.tail(math.trunc(len(df)*0.2))\n",
    "val_df = test_df.tail(BATCH_SIZE*4)\n",
    "\n",
    "# Convert the subset DataFrame to a dictionary\n",
    "train_dict = train_df.to_dict(orient='list')\n",
    "test_dict = test_df.to_dict(orient='list')\n",
    "val_dict = val_df.to_dict(orient='list')\n",
    "\n",
    "# Fit the label encoder on the labels in the training dataset\n",
    "# Transform the string labels into integer representations\n",
    "\n",
    "label_encoder.fit(train_dict['label'])\n",
    "train_dict['label'] = label_encoder.transform(train_dict['label'])\n",
    "\n",
    "label_encoder.fit(test_dict['label'])\n",
    "test_dict['label'] = label_encoder.transform(test_dict['label'])\n",
    "\n",
    "label_encoder.fit(val_dict['label'])\n",
    "val_dict['label'] = label_encoder.transform(val_dict['label'])\n",
    "\n",
    "\n",
    "train_dict['label'] = [int(x) for x in train_dict['label']]\n",
    "test_dict['label'] = [int(x) for x in test_dict['label']]\n",
    "val_dict['label'] = [int(x) for x in val_dict['label']]\n",
    "\n",
    "\n",
    "# Create a Dataset from the dictionary\n",
    "train_dataset = datasets.Dataset.from_dict(train_dict)\n",
    "test_dataset = datasets.Dataset.from_dict(test_dict)\n",
    "val_dataset = datasets.Dataset.from_dict(val_dict)\n",
    "\n",
    "print(train_dataset)\n",
    "print(test_dataset)\n",
    "print(val_dataset)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL, use_fast=True)\n",
    "\n",
    "train_dataset = train_dataset.map(lambda e: tokenizer(e['text'], truncation=True, padding=True), batched=True)\n",
    "test_dataset = test_dataset.map(lambda e: tokenizer(e['text'], truncation=True, padding=True), batched=True)\n",
    "val_dataset = val_dataset.map(lambda e: tokenizer(e['text'], truncation=True, padding=True), batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40a28de8-a4de-4613-afa7-e756a3c870c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sep2022 were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sep2022 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7ff4e4385790>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_130/29288982.py\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, RobertaConfig\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Load the tokenizer and model configuration\n",
    "tokenizer = AutoTokenizer.from_pretrained('cardiffnlp/twitter-roberta-base-sep2022')\n",
    "config = RobertaConfig.from_pretrained('cardiffnlp/twitter-roberta-base-sep2022')\n",
    "\n",
    "# Create the model for sequence classification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'cardiffnlp/twitter-roberta-base-sep2022',\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "# Modify the model's classification head\n",
    "num_labels = 2  # Adjust this based on your specific classification task\n",
    "model.classifier = torch.nn.Linear(config.hidden_size, num_labels)\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "# Create DataLoaders for training and evaluation\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "eval_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "print(train_dataloader)\n",
    "\n",
    "# Define the optimizer and learning rate\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Fine-tuning loop\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        inputs, labels = batch\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluation loop\n",
    "model.eval()\n",
    "predictions = []\n",
    "ground_truth = []\n",
    "with torch.no_grad():\n",
    "    for batch in eval_dataloader:\n",
    "        inputs, labels = batch\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        predicted_labels = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "        predictions.extend(predicted_labels.tolist())\n",
    "        ground_truth.extend(labels.tolist())\n",
    "\n",
    "# Calculate evaluation metrics based on predictions and ground truth labels\n",
    "accuracy = (torch.tensor(predictions) == torch.tensor(ground_truth)).float().mean().item()\n",
    "\n",
    "# Print the evaluation results\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b223148d-c1ef-417a-b465-423ac8024c44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
