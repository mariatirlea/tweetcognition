{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "050a16a2-0353-48aa-b91a-0a96d333ff50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "Requirement already satisfied: openpyxl in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from openpyxl) (1.1.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "Requirement already satisfied: torch in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (2.0.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (2.14.3)\n",
      "Requirement already satisfied: jinja2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: sympy in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (11.7.91)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (11.7.4.91)\n",
      "Requirement already satisfied: typing-extensions in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: networkx in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (10.2.10.91)\n",
      "Requirement already satisfied: filelock in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (3.12.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: setuptools in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (67.6.1)\n",
      "Requirement already satisfied: wheel in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.40.0)\n",
      "Requirement already satisfied: cmake in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from triton==2.0.0->torch) (3.26.3)\n",
      "Requirement already satisfied: lit in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from triton==2.0.0->torch) (16.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "Requirement already satisfied: accelerate in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (0.19.0)\n",
      "Requirement already satisfied: psutil in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: torch>=1.6.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from accelerate) (2.0.1)\n",
      "Requirement already satisfied: pyyaml in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from accelerate) (5.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from accelerate) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from accelerate) (23.0)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch>=1.6.0->accelerate) (11.7.4.91)\n",
      "Requirement already satisfied: networkx in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch>=1.6.0->accelerate) (3.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch>=1.6.0->accelerate) (11.7.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch>=1.6.0->accelerate) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch>=1.6.0->accelerate) (11.10.3.66)\n",
      "Requirement already satisfied: typing-extensions in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch>=1.6.0->accelerate) (4.5.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch>=1.6.0->accelerate) (11.7.99)\n",
      "Requirement already satisfied: jinja2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch>=1.6.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: filelock in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch>=1.6.0->accelerate) (3.12.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch>=1.6.0->accelerate) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch>=1.6.0->accelerate) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch>=1.6.0->accelerate) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch>=1.6.0->accelerate) (2.14.3)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch>=1.6.0->accelerate) (2.0.0)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch>=1.6.0->accelerate) (10.2.10.91)\n",
      "Requirement already satisfied: sympy in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch>=1.6.0->accelerate) (1.12)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch>=1.6.0->accelerate) (11.7.101)\n",
      "Requirement already satisfied: setuptools in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->accelerate) (67.6.1)\n",
      "Requirement already satisfied: wheel in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->accelerate) (0.40.0)\n",
      "Requirement already satisfied: cmake in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (3.26.3)\n",
      "Requirement already satisfied: lit in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (16.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pywidgets (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers --quiet\n",
    "!pip install datasets --quiet\n",
    "!pip install evaluate --quiet\n",
    "!pip install openpyxl\n",
    "!pip install torch\n",
    "!pip install -U scikit-learn scipy matplotlib --quiet\n",
    "!pip install --upgrade accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71782988-136c-4fc8-bd74-aa410fc838f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments, EarlyStoppingCallback, set_seed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import evaluate\n",
    "from sklearn.metrics import classification_report\n",
    "import datasets\n",
    "import math\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58eae7c6-b01c-4739-af43-6d22aa28e0c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text     0\n",
      "label    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Enthusiasm is rare, Endurance is rare.</td>\n",
       "      <td>GRADUATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>That amazing moment!</td>\n",
       "      <td>GRADUATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Work hard. Stay humble.;.;.;#graduating #gradu...</td>\n",
       "      <td>GRADUATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@nomi_9867 @BVBoni17 Education is key üñçÔ∏è</td>\n",
       "      <td>GRADUATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Big journey begins with small steps.;.;.;#gra...</td>\n",
       "      <td>GRADUATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>Was just told that my dear friend, Dr. Ramin O...</td>\n",
       "      <td>DEATH_OF_A_LOVED_ONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>@sy_fyn_ity I'm so sorry, how awful. My dad di...</td>\n",
       "      <td>DEATH_OF_A_LOVED_ONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>my other grandpa just died by a heart attack</td>\n",
       "      <td>DEATH_OF_A_LOVED_ONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>My grandma died last night. I knew it was comi...</td>\n",
       "      <td>DEATH_OF_A_LOVED_ONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>I'm so upset because finally everything was go...</td>\n",
       "      <td>DEATH_OF_A_LOVED_ONE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>876 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text                 label\n",
       "0               Enthusiasm is rare, Endurance is rare.            GRADUATION\n",
       "1                                 That amazing moment!            GRADUATION\n",
       "2    Work hard. Stay humble.;.;.;#graduating #gradu...            GRADUATION\n",
       "3             @nomi_9867 @BVBoni17 Education is key üñçÔ∏è            GRADUATION\n",
       "4     Big journey begins with small steps.;.;.;#gra...            GRADUATION\n",
       "..                                                 ...                   ...\n",
       "871  Was just told that my dear friend, Dr. Ramin O...  DEATH_OF_A_LOVED_ONE\n",
       "872  @sy_fyn_ity I'm so sorry, how awful. My dad di...  DEATH_OF_A_LOVED_ONE\n",
       "873      my other grandpa just died by a heart attack   DEATH_OF_A_LOVED_ONE\n",
       "874  My grandma died last night. I knew it was comi...  DEATH_OF_A_LOVED_ONE\n",
       "875  I'm so upset because finally everything was go...  DEATH_OF_A_LOVED_ONE\n",
       "\n",
       "[876 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### CLEANUP\n",
    "\n",
    "\n",
    "# Load labeled dataset of tweets related to specific life events\n",
    "df = pd.read_excel('dataset/LabeledTweets.xlsx', names=['text', 'label'])\n",
    "print(df.isna().sum())  # print the number of NaN values in each column\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9660a83b-7efb-4cfd-83b6-da557ce3bbec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>@bennyjohnson - congratulations are in order! ...</td>\n",
       "      <td>PREGNANCY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>To get to marry my best friend is a dream tha...</td>\n",
       "      <td>WEDDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>Unfortunate turn of events ‚Äì my laptop, contai...</td>\n",
       "      <td>DAMEGED_OR_STOLEN_PROPERTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>@gachaheat_zay will marry you!</td>\n",
       "      <td>WEDDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>Health challenges can feel isolating, but I've...</td>\n",
       "      <td>SERIOUS_HEALTH_CONDITION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Enthusiasm is rare, Endurance is rare.</td>\n",
       "      <td>GRADUATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>What's the craziest \"job quitting\" story you'...</td>\n",
       "      <td>QUIT_JOB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>Today, I became the proud owner of a classic c...</td>\n",
       "      <td>CAR_PURCHASE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Four More shots! Actress gets engaged : Share...</td>\n",
       "      <td>ENGAGEMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>‚ÄúMy divorce is finally final; it‚Äôs a weird, wi...</td>\n",
       "      <td>DIVORCE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>876 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text   \n",
       "840  @bennyjohnson - congratulations are in order! ...  \\\n",
       "252   To get to marry my best friend is a dream tha...   \n",
       "391  Unfortunate turn of events ‚Äì my laptop, contai...   \n",
       "137                     @gachaheat_zay will marry you!   \n",
       "794  Health challenges can feel isolating, but I've...   \n",
       "..                                                 ...   \n",
       "0               Enthusiasm is rare, Endurance is rare.   \n",
       "185   What's the craziest \"job quitting\" story you'...   \n",
       "417  Today, I became the proud owner of a classic c...   \n",
       "162   Four More shots! Actress gets engaged : Share...   \n",
       "855  ‚ÄúMy divorce is finally final; it‚Äôs a weird, wi...   \n",
       "\n",
       "                          label  \n",
       "840                   PREGNANCY  \n",
       "252                     WEDDING  \n",
       "391  DAMEGED_OR_STOLEN_PROPERTY  \n",
       "137                     WEDDING  \n",
       "794    SERIOUS_HEALTH_CONDITION  \n",
       "..                          ...  \n",
       "0                    GRADUATION  \n",
       "185                    QUIT_JOB  \n",
       "417                CAR_PURCHASE  \n",
       "162                  ENGAGEMENT  \n",
       "855                     DIVORCE  \n",
       "\n",
       "[876 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83d780af-4b9d-4395-978b-98c3e7228b46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 700\n",
      "})\n",
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 175\n",
      "})\n",
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 64\n",
      "})\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "cardiffnlBATCH_SIZEp/twitter-roberta-base-sep2022 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo with `use_auth_token` or log in with `huggingface-cli login` and pass `use_auth_token=True`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/huggingface_hub/utils/_errors.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/cardiffnlBATCH_SIZEp/twitter-roberta-base-sep2022/resolve/main/tokenizer_config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[1;32m   1194\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m                 metadata = get_hf_file_metadata(\n\u001b[0m\u001b[1;32m   1196\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout)\u001b[0m\n\u001b[1;32m   1540\u001b[0m     )\n\u001b[0;32m-> 1541\u001b[0;31m     \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/huggingface_hub/utils/_errors.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    290\u001b[0m             )\n\u001b[0;32m--> 291\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-645cf34c-6e8578082b6e916568b7be69)\n\nRepository Not Found for url: https://huggingface.co/cardiffnlBATCH_SIZEp/twitter-roberta-base-sep2022/resolve/main/tokenizer_config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_974/3279891488.py\u001b[0m in \u001b[0;36m<cell line: 42>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_fast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0mtokenizer_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tokenizer_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"_commit_hash\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenizer_config\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mget_tokenizer_config\u001b[0;34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, **kwargs)\u001b[0m\n\u001b[1;32m    485\u001b[0m     ```\"\"\"\n\u001b[1;32m    486\u001b[0m     \u001b[0mcommit_hash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m     resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m    488\u001b[0m         \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0mTOKENIZER_CONFIG_FILE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m         raise EnvironmentError(\n\u001b[0m\u001b[1;32m    434\u001b[0m             \u001b[0;34mf\"{path_or_repo_id} is not a local folder and is not a valid model identifier \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0;34m\"listed on 'https://huggingface.co/models'\\nIf this is a private repository, make sure to \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: cardiffnlBATCH_SIZEp/twitter-roberta-base-sep2022 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo with `use_auth_token` or log in with `huggingface-cli login` and pass `use_auth_token=True`."
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "BATCH_SIZE = 16\n",
    "MODEL = 'cardiffnlp/twitter-roberta-base-sep2022'\n",
    "dataset_dict = {}\n",
    "\n",
    "train_df = df.head(math.trunc(len(df)*0.8))\n",
    "test_df = df.tail(math.trunc(len(df)*0.2))\n",
    "val_df = test_df.tail(BATCH_SIZE*4)\n",
    "\n",
    "# Convert the subset DataFrame to a dictionary\n",
    "train_dict = train_df.to_dict(orient='list')\n",
    "test_dict = test_df.to_dict(orient='list')\n",
    "val_dict = val_df.to_dict(orient='list')\n",
    "\n",
    "# Fit the label encoder on the labels in the training dataset\n",
    "# Transform the string labels into integer representations\n",
    "\n",
    "label_encoder.fit(train_dict['label'])\n",
    "train_dict['label'] = label_encoder.transform(train_dict['label'])\n",
    "\n",
    "label_encoder.fit(test_dict['label'])\n",
    "test_dict['label'] = label_encoder.transform(test_dict['label'])\n",
    "\n",
    "label_encoder.fit(val_dict['label'])\n",
    "val_dict['label'] = label_encoder.transform(val_dict['label'])\n",
    "\n",
    "\n",
    "train_dict['label'] = [int(x) for x in train_dict['label']]\n",
    "test_dict['label'] = [int(x) for x in test_dict['label']]\n",
    "val_dict['label'] = [int(x) for x in val_dict['label']]\n",
    "\n",
    "\n",
    "# Create a Dataset from the dictionary\n",
    "train_dataset = datasets.Dataset.from_dict(train_dict)\n",
    "test_dataset = datasets.Dataset.from_dict(test_dict)\n",
    "val_dataset = datasets.Dataset.from_dict(val_dict)\n",
    "\n",
    "print(train_dataset)\n",
    "print(test_dataset)\n",
    "print(val_dataset)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL, use_fast=True)\n",
    "\n",
    "train_dataset = train_dataset.map(lambda e: tokenizer(e['text'], truncation=True, padding=True), batched=True)\n",
    "test_dataset = test_dataset.map(lambda e: tokenizer(e['text'], truncation=True, padding=True), batched=True)\n",
    "val_dataset = val_dataset.map(lambda e: tokenizer(e['text'], truncation=True, padding=True), batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a28de8-a4de-4613-afa7-e756a3c870c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, RobertaConfig\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Load the tokenizer and model configuration\n",
    "tokenizer = AutoTokenizer.from_pretrained('cardiffnlp/twitter-roberta-base-sep2022')\n",
    "config = RobertaConfig.from_pretrained('cardiffnlp/twitter-roberta-base-sep2022')\n",
    "\n",
    "# Create the model for sequence classification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'cardiffnlp/twitter-roberta-base-sep2022',\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "# Modify the model's classification head\n",
    "num_labels = 2  # Adjust this based on your specific classification task\n",
    "model.classifier = torch.nn.Linear(config.hidden_size, num_labels)\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "# Create DataLoaders for training and evaluation\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "eval_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "print(train_dataloader)\n",
    "\n",
    "# Define the optimizer and learning rate\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Fine-tuning loop\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        inputs = torch.tensor(batch['text'])\n",
    "        labels = torch.tensor(batch['label'])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluation loop\n",
    "model.eval()\n",
    "predictions = []\n",
    "ground_truth = []\n",
    "with torch.no_grad():\n",
    "    for batch in eval_dataloader:\n",
    "        inputs = batch['text']\n",
    "        labels = batch['label']\n",
    "        outputs = model(inputs)\n",
    "        predicted_labels = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "        predictions.extend(predicted_labels.tolist())\n",
    "        ground_truth.extend(labels.tolist())\n",
    "\n",
    "# Calculate evaluation metrics based on predictions and ground truth labels\n",
    "accuracy = (torch.tensor(predictions) == torch.tensor(ground_truth)).float().mean().item()\n",
    "\n",
    "# Print the evaluation results\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b223148d-c1ef-417a-b465-423ac8024c44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
